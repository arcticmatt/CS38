%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Preamble
\documentclass{article}
\usepackage{amsmath,amssymb,amsthm,fullpage}
\usepackage[a4paper,bindingoffset=0in,left=1in,right=1in,top=1in,
bottom=1in,footskip=0in]{geometry}
\newtheorem*{prop}{Proposition}
%\newcounter{Examplecount}
%\setcounter{Examplecount}{0}
\newenvironment{discussion}{\noindent Discussion.}{}
\pagenumbering{gobble}
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Problem 1
\section*{Problem 1, CS38 Midterm, Matt Lim}
\begin{description}
    \item[(a)]
        See attached sheet.
    \item[(b)]
        Here is pseudo-code for our algorithm. Let $A$ be the adjacency matrix
        of the graph.
        \begin{enumerate}
            \item
                We begin by squaring $A$ to get the matrix $A^2$. This is
                $O(n^{\log _27)}$.
            \item
                We then iterate down the diagonal of $A^2$. For each column/row
                $i$ that has a value $v$ greater than or equal to $2$ on the
                diagonal, we will label the corresponding row and column on the
                matrix $A$ with $v$. We will label every other column and row
                with $0$. This label corresponds to how many edges are going
                into a given node (so if a row is labeled with $5$,  there are
                $5$ edges going into it)
                This takes time $O(n)$. Note that from here on, we
                will be working with the matrix $A$.
            \item Then, for each row with a value greater than or equal to two, we will iterate
                through its columns. First, we will reset its value to zero.
                Then, for each of its columns (with an index not equal to
                the current row index) with a nonzero value in it, we will
                add one to the row's value. After we have finished reassigning
                the row values, we will copy those values over to the
                corresponding columns. We will then sort the rows
                again in ascending order. This is $O(n^2\log n)$.
            \item
                We will iterate through the rows in ascending order. For each
                row $R$ with a value greater than or equal to $1$, we will iterate
                through its columns. Let $i$ be the index of $R$. If we encounter a
                nonzero value in a column
                that a) is labeled with a nonzero value, b) is not marked by $X$
                (see the end of this item), and c) whose
                index is not $i$, we will store its index in a list $L$. Then, having
                iterated through each column of $R$, we will do the following.
                For every pair of indices
                $j_1$ and $j_2$ in $L$, we will check the $(j_1,j_2)$ position of
                the matrix. If there is a one at that position, then our graph
                has a triangle. If we do this for every pair of indices and we
                find no triangle, then we will mark column $i$ with an $X$.
                \begin{itemize}
                    \item We claim that this step runs in $O(n^2)$. To see why,
                        consider the following argument. When iterating through
                        any column, we will never generate a list with more than
                        $2$ items. This is because we go through in ascending
                        order and because we only add items from columns that
                        are labeled with a nonzero value. It is also because we
                        $X$ out columns once we discover that their
                        corresponding node is not in a triangle.

                        Basically, we must always have
                        at least one node of nonzero value that is
                        attached to at most two nodes of nonzero values that are
                        not crossed out. That is, we must always have at least
                        one node with a value of at most two and at least
                        one. The
                        only other cases are when there is no such node,
                        in which case we are done iterating through the rows, or when the graph is
                        infinite, which we do not have.

                        Since we never generate a list with more than $2$ items,
                        then going through each row only takes $O(n)$. And since
                        there are $n$ rows, we get the desired time value of
                        $O(n^2)$ for
                        the whole operation.
                \end{itemize}
        \end{enumerate}

        If we follow through the steps, we can see that this algorithm runs in
        the desired time of $O(n^{\alpha})$, for some $\alpha < 3$.

        So we have given the algorithm and given time bounds. Now we will prove
        correctness by induction. We will induct on $n$, the number of nodes in
        our graph. We will let the base case be $n = 3$. If we don't have a
        triangle, then in step 5 of our algorithm, we will never add more than
        one item to our list, making it impossible for our algorithm to tell us
        we have a triangle. This is because there cannot be two nodes that are
        connected to two other nodes - otherwise we would have a triangle. If we
        do have a triangle, then every row will be labeled with a value greater
        than or equal to $2$. Then it is obvious that our step 5 detects a
        triangle. Now for the inductive assumption. Assume that our algorithm
        works for all graphs with $3 \leq k < n$. Now we must prove that our
        algorithm works for $n$. So, consider a graph of size $n-1$. By our
        inductive assumption our algorithm correctly tells us if this graph has
        a triangle in it. Now consider what happens when we add one more node,
        and any number of edges. Then we can just test every subgraph of
        $n-1$ nodes and see if any contain a triangle. By the inductive
        assumption, our algorithm gives us the right answer for $n-1$ nodes.
        Thus, by induction, we have that our algorithm works for graphs whose
        nodes number greater than or equal to three (if a graph has less than
        three nodes it obviously does not have a triangle).
\end{description}
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Problem 2
\section*{Problem 2, CS38 Midterm, Matt Lim}
\begin{description}
    \item[(a)]
        We will assume that every element $e \in E$ is mentioned in some subset
        of $I$. This means that for every element $e \in E$, the set $\{e\}$
        is in $I$ (by the second axiom of matroids). Now we will show that the set system on
        $E' = E \backslash \{e\}$ defined by
        \[ I' = \{A : (A \cup \{e\}) \in I\} \]
        is a matroid.

        First we will show that axiom one holds. For $\varnothing \in I'$ to be
        true, then $\varnothing \cup \{e\} = \{e\} \in I$ must be true. And this
        indeed is true by the assumption we made. So axiom one holds.

        Now we will show that the second axiom holds. Let us assume that $A \in
        I'$. Now we must show that every subset $B \subseteq A$ is also in $I'$.
        So, since $A \in I'$, we have that $A' = A \cup \{e\} \in I$. This means that
        every subset $B' \subseteq A'$ is also in $I$, since $I$ is a matroid.
        Then it follows that every subset of $A$ is in $I$. It also follows that
        every subset of $A$ unioned with $\{e\}$ is in $I$. This means that
        every subset of $A$ is in $I'$. So the second axiom holds.

        Finally, we will show that the third axiom holds. So, let $A$ and $B$ be
        subsets in $I'$ with $|B| > |A|$. We must show that there exists $x \in
        B \backslash A$ such that $A \cup \{x\}$ is in $I'$. Let us consider
        $A' = A \cup \{e\} \in I$ and $B' = B \cup \{e\} \in I$. Then we have
        that there exists $x \in B' \backslash A'$ such that $A' \cup \{x\}$ is
        in $I$, where $x \neq e$. Then it follows that we can union this $x$
        with our original $A$ to make $A \cup \{x\}$. Then we can say that $A
        \cup \{x\}$ is in $I'$, since $A \cup \{x\} = (A' \cup \{x\}) \backslash
        \{e\}$. Thus all three axioms hold and we have that $I'$ is a matroid.
    \item[(b)]
        Note that for this problem, we will assume that $F$ does not
        contain a cycle. We will first argue that the subsets of $G$'s edges that, together with
        $F$, form spanning trees, constitute the bases of a matroid $I$. So, let
        these subsets be the bases of $I$ (they have the same cardinality
        because all spanning trees have $|V| - 1$ edges and they are clearly
        independent sets), and let $I$ contain all subsets of them.

        We will first consider the first axiom. We have that $G$ has some set
        $A$ of edges that, together with $F$, forms a spanning tree. If $A$ is
        already the empty set then we are done. If $A$ is not the empty set, then
        we have that the empty set is the subset of $A$, since the empty set if
        a subset of any other set. So the empty set must be in $I$. Thus the
        first axiom holds.

        We will now consider the second axiom. This is true by how we defined
        $I$. We defined $I$ to contain the subsets of the subsets $G$'s edges that, together
        with $F$, form spanning trees. Thus if $A \in I$ then every subset $B
        \subseteq A$ is also in $I$. So the second axiom holds.

        Finally, we will consider the third axiom. So, let $A$ and $B$ be
        subsets in $I$ with $|B| > |A|$. Since $B$ has more edges than $A$ and
        is the subset of a subset of $G$ that forms a spanning tree with $F$, it
        spans at least one more vertex than $A$ (that is not spanned by $F$).
        That is, there is an edge $e$ in
        $B$ that connects a vertex $v$ which is not connected by any edge in
        $A$. So if we consider $A \cup \{e\}$, we can see that it has no cycles,
        since $e$ adds an edge to a vertex $v$ which was previously not reached
        by $A$. Thus it is clear that $A \cup \{e\} \in I$, since by adding $e$
        we span one more vertex not spanned by $F$ and do not create any cycles.

        \vspace{8mm}
        Now we will use $I$ to find the desired minimum cost tree.

         Here is a way to formulate this minimum cost spanning tree problem as the
        problem of finding a maximum weight independent set in $I$. We will
        give nonnegative integer
        weights for each element of the universe $E \backslash F$, which will correspond to the
        edge weights of $G$. That is, each element in the matroid will
        represent an edge in the graph, and will be given a positive integer weight.
        However, these edge weights will not be the
        same as the edge weights of the graph. Instead, we will ``flip'' the
        weights. That is, we will take the maximum edge weight from the graph,
        add one to it,
        and subtract the weight of each edge to find the new weight of each
        edge. So, if the max edge weight is $w_{max}$, and we have an edge with
        weight $w$ in the graph, the corresponding weight in the matroid is $w_{matroid edge} =
        w_{max} + 1 - w$. We can rewrite this as $w_{matroid edge} = w_0 - w$, where
        $w_0 = w_{max} + 1$.
        Then we have that all weights are positive,
        and that finding the maximum weight independent set in this
        matroid will give the minimum cost set of edges that, together with $F$,
        forms a spanning tree.
        To see a short proof of this, consider the
        following. Each maximal independent subset $A \in I$ corresponds to a set of
        $|V| - 1 - |F|$ edges. Then we have the following (where $w'(e)$
        represents the weight of the edge $e$ in the matroid, $w(e)$ represents the
        weight of the edge $e$ in the graph, $w'(A)$ represents the sum of the
        matroid edge weights, and $w(A)$ represents the sum of the graph edge
        weights):
        \[ w'(A) = \sum_{e \in A} w'(e) \]
        \[ = \sum_{e \in A} (w_0 - w(e)) \]
        \[ = (|V| - 1 - |F|)w_0 - \sum_{e \in A} w(e) \]
        \[ = (|V| - 1 - |F|)w_0 - w(A) \]
        Clearly, maximizing $w'(A)$ must minimize $w(A)$.

        Now we will prove time bounds and correctness of the greedy algorithm.
        Assigning weights to all the edges is $O(m)$. Then, we proved in set
        number 2 problem number 2b that the greedy algorithm to find the maximum weight
        independent set in a matroid is $O(m \log m)$, where $m$ is the number
        of edges in $G$. In that same problem we also proved correctness. Since
        we have that our greedy algorithm is correct, and given the way we
        defined our edge weights in $I$, it follows that finding a
        maximal independent subset $A$ of $I$ is the same as finding the minimum
        weight subset of $G$'s edges that form a spanning tree with $F$.
        Thus our proof is complete.
\end{description}
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Problem 3
\section*{Problem 3, CS38 Midterm, Matt Lim}
\begin{description}
    \item[(a)]
        Here is our algorithm.
        \begin{enumerate}
            \item First we will sort each list. This is $O(n\log n)$.
            \item We will then make $n$ new lists. Let $A = a_1, \dots, a_n$,
                $B = b_1, \dots, b_n$, and $C = c_1, \dots, c_n$ be the newly sorted
                lists. Then we will have $L_1 = a_1 + b_1, a_1 + b_2, \dots, a_1
                + b_n$, $L_2 = a_2 + b_1, a_2 + b_2, \dots, a_2 + b_n$, etc.
                etc. up until $L_n = a_n + b_1, a_n + b_2, \dots, a_n + b_n$.
                This is $O(n^2)$.
            \item Note that all the lists we made in the previous step are
                sorted. Thus we can do the following.
                We will merge all our lists into one big sorted list. We
                will call this list $L$. We can see that $L$ will have order
                $n^2$ elements. Thus this step is $O(n^2)$.
            \item Then, we will iterate through list $C$. For each element $c_i
                \in C$, we will binary search list $L$ for $-c_i$. If this
                search succeeds for any $c_i$, then there exist $i,j,k$ such that
                $a_i + b_j + c_k = 0$. This is time $O(n\log n^2) =
                O(n\log n)$.
        \end{enumerate}
        Observe that the dominating time bound above is $O(n^2)$. Thus we have
        that our algorithm runs in time $O(n^2)$.
        So we have given the algorithm and shown the time bound for it. Now we
        will show correctness. We have that our list $L$ contains every possible
        sum of one element from $A$ and one element from $B$. In other words,
        $L$ contains every possible $a_i + b_j$. Therefore, we need only to know
        if any element from $L$ plus any element from $C$ sums to $0$. That is,
        each must check if there exists $i,j$ such that $l_i + c_j = 0$, $l_i
        \in L$. Our algorithm does exactly this, checking if if there exists an
        $l_i = -c_j$ for every $c_j \in C$. Thus it follows that our algorithm
        works correctly.
    \item[(b)]
        Note that for this problem we will assume that $M > n$. Now here is our
        algorithm.
        \begin{enumerate}
            \item Let $A = a_1, \dots, a_n$,
                $B = b_1, \dots, b_n$, and $C = c_1, \dots, c_n$ be our lists.
                We will begin by forming two polynomials:
                \[ P_1(X) = \sum_{i \in A} X^{i+M} \]
                \[ P_2(X) = \sum_{i \in B} X^{i+M} \]
                Shifting the degree ensures we have no negative degrees. Forming
                these polynomials is time $O(M)$.
            \item We will then perform fast polynomial multiplication, and form a new
                polynomial:
                \[ P(X) = P_1(X) \cdot P_2(X) \]
                This is $O(M \log M)$ using fast polynomial multiplication as
                seen in lecture, since the largest degree possible is $2M$
                and the smallest possible degree is $0$. This is because
                all of the integers lie in the range $[-M, M]$ and because of
                how we shifted the degrees in the step above.
            \item We will then iterate through $P(X)$ and form a list $L$ of all
                the degrees/powers, with each one shifted down by $2M$. This
                is because we originally shifted all the powers up by $M$.
                We will assume that $P(X)$ has its terms
                sorted in order of ascending degree (e.g. $x + x^2 + x^4 + x^7
                \dots$). Then we have that $L$ is sorted in ascending order.
                Making this list is $O(M)$, since our polynomial has maximum
                degree $M$ and minimum degree $-M$, and we are assuming that
                $M > n$.
            \item Then, we will iterate through list $C$. For each element $c_i
                \in C$, we will binary search list $L$ for $-c_i$. If this
                search succeeds for any $c_i$, then there exist $i,j,k$ such that
                $a_i + b_j + c_k = 0$. This is time $O(M \log M)$, since we are
                assuming that $M>n$.
        \end{enumerate}
        Observe that the dominating time bound above is $O(M \log M)$. Thus we have
        that our algorithm runs in time $O(M \log M)$.
        So we have given the algorithm and shown the time bound for it. Now we
        will show correctness. Consider the polynomial $P(X)$ as seen in item 2.
        Let $D_P$ be the list of the degrees of the terms of $P(X)$. For
        example, for $P(X) = x + x^7$, $D_P = 1, 7$. Then we have that $D_P$
        contains every possible sum of one element from $A$ and one element from
        $B$, except with each sum shifted up by $2M$. But then we can just shift
        each number in the list down by $2M$ so that it actually contains every
        possible sum, which is exactly what we do in our algorithm.
        And since $L = D_P$, we have that $L$ contains every possible $a_i
        + b_j$. Therefore, we need only to know
        if any element from $L$ plus any element from $C$ sums to $0$. That is,
        each must check if there exists $i,j$ such that $l_i + c_j = 0$, $l_i
        \in L$. Our algorithm does exactly this, checking if if there exists an
        $l_i = -c_j$ for every $c_j \in C$. Thus it follows that our algorithm
        works correctly.

\end{description}
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Problem 3
\section*{Problem 4, CS38 Midterm, Matt Lim}
We will use the term ``weight of a triangle'' to indicate the sum of all three
of its edges. Now, here is pseudo-code for our algorithm.

\vspace{5mm}
\noindent \textbf{Lightest-Triangle(P: set of n points in the plane)}
\begin{enumerate}
    \item sort by x coordinate and split equally into \textbf{L} and \textbf{R} subsets
    \item $(a,b,c)$ = \textbf{Lightest-Triangle(L)}
    \item $(d,e,f)$ = \textbf{Lightest-Triangle(R)}
    \item $D_1 = d(a,b) + d(b,c) + d(c,a)$
    \item $D_2 = d(d,e) + d(e,f) + d(f,d)$
    \item $D = min(D_1, D_2)$
    \item scan \textbf{P} by x coordinate to find \textbf{M}: points within $D/2$ of midline
    \item sort \textbf{M} by y coordinate
    \item Starting at the point with the highest y coordinate (call it $v$),
        compute lightest triangle containing $v$ using all the points within
        $24$ positions ahead in the sorted list. Then iterate through the sorted
        list and do this for every other point. Call the lightest triangle found
        by this iteration $(g,h,i)$.
    \item return best among $(a,b,c)$, $(d,e,f)$, and $(g,h,i)$.
\end{enumerate}

\vspace{8mm}
We will now prove time bounds for this theorem. We have that the time is
\[ T(n) = 2T(n/2) + \text{ time for middle } + O(n \log n) \]
where the $O(n \log n)$ is the time it takes to perform the splits and sorts.
Our goal is to show that the time for middle is $O(n \log n)$. To do this,
we need only to look at our algorithm. For each point in the middle area, we
compare at most $\sum_{i=1}^{24} i$ triangles. This is a constant number. And
since the number of points in the middle area is at most $n$, we have that the
middle area takes linear time. So then we get that
\[ T(n) = 2T(n/2) + O(n \log n) \]
Then by the proof shown in class (lecture 7, slide 42) we have that
\[ T(n) \leq c \cdot n \cdot \log^2 n \]
So we have that our algorithm runs in time $O(n \log^2 n)$.

\vspace{8mm}
Now we will prove correctness. Let us consider the middle area; that is, the
area composed within distance $D/2$ of the midline (making the total area width
$D$). We will divide this area up into $D/4 \times D/4$ boxes. Now we can make
the following observations. First, we have that no $3$ points lie in the same
box. If so, then they would form a triangle of weight less than $D$, which is
impossible due to how we set things up. Next, we have that if $2$ points are
within $\ge 24$ positions of each other in list sorted by $y$ coordinate, then
they must be separated by $\ge 2$ rows. Then we have that their distance is $>
D/2$. Then by the triangle inequality, any triangle containing these two points
must have a weight $>D$. So we don't need to consider these points. In other
words, the only possible points that we must consider when going down the sorted
list are the points with 24 positions of each other. Thus it follows that our
algorithm is correct, since we compute the lightest triangle of the left half,
right half, and middle correctly, and take the minimum.
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Problem 3
\section*{Problem 5, CS38 Midterm, Matt Lim}
Let $x$ be some set vertex in $G$. We will let it be $v_k$ for some $1 \le k \le n$.
Let $HC(i,S)$ be 0 if there
is no path from $x$ to $v_i$ that passes through all of set $S$
and 1 if there is such a path. We
will organize our subsets of vertices in the table in the following way. $S_1,
S_2, \dots, S_n$ will be the subsets containing only a single vertex. Next will
come the subsets containing two vertices, then three, and so on.
Here is pseudo-code for our algorithm.

\vspace{5mm}
\noindent \textbf{Ham-cycle(G)}
\begin{enumerate}
    \item Test $G$ to see if it is a strong connected component. If yes,
        continue. If not, return false.
    \item $HC(i,j) = 0$ for all $i,j$
    \item for $i=1$ to $n$
    {\setlength\itemindent{25pt} \item for $S=S_1$ to $S_n$ }
    {\setlength\itemindent{50pt} \item for all simple paths (excluding double
    counting the start vertex) from $x$ to $v_i$ }
    {\setlength\itemindent{75pt} \item if path contains $S$ (not counting
    starting vertex) }
    {\setlength\itemindent{100pt} \item $HC(i,S) = 1$, break out of loop }

    \item for $i=1$ to $n$
    {\setlength\itemindent{25pt} \item for $S=S_{n+1}$ to $S_{2^n}$ }
    {\setlength\itemindent{50pt} \item int $ham = 1$}
    {\setlength\itemindent{50pt} \item for each element $e \in S$}
    {\setlength\itemindent{75pt} \item if $HC(i,\{e\}) = 0$ }
    {\setlength\itemindent{75pt} \item $ham = 0$ }
    {\setlength\itemindent{50pt} \item $HC(i,S) = ham$ }
    \item if $HC(n,S_{2^n}) = 1$
    {\setlength\itemindent{25pt} \item return true}
    \item return false

\end{enumerate}

\vspace{5mm}
Now we will show that this algorithm runs in $O(n^2 2^n)$ time. We showed in
class that determining if a graph is strongly connected is $O(n+m)$. Now, consider
lines 3-7. Here we loop through order $n^2$ times. Then, for each time through
the loop, we consider less than or equal to order $2^n$ paths. So the time for
this entire loop is $O(n^2 2^n)$. Next, consider lines 8-14. Here we loop through order
$n \cdot 2^n$ times. Then, for each time through the loop, we look at up to $n$
elements. So the time for this entire loop is also $O(n^2 2^n)$. So we have that
the total time for the algorithm is $O(n^2 2^n)$.

Now we will show correctness. The first thing we do is check if $G$ is
strongly connected. This is because if $G$ has a Hamilton cycle, then
it must be strong connected. This is because if $G$ has a Hamilton cycle, then
every vertex can be reached from every other vertex by just going along the
cycle. Now, consider the first loop, lines 3-7. We calculate
these subproblems manually, and we can clearly see that for this part of the
table, we have the correct answers. Now consider the second loop, lines 8-14.
Filling in this part of the table relies entirely on the first part. Basically,
for each subproblem, we do the following. We consider each element of the subset
$S$ at a time. For each element, we see if it is on some simple path from $x$ to
$v_i$ by referencing the first $n \times n$ block of the table that we filled in
manually.

\newpage
\end{document}
