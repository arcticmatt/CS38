%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Preamble
\documentclass{article}
\usepackage{amsmath,amssymb,amsthm,fullpage}
\usepackage[a4paper,bindingoffset=0in,left=1in,right=1in,top=1in,
bottom=1in,footskip=0in]{geometry}
\newtheorem*{prop}{Proposition}
%\newcounter{Examplecount}
%\setcounter{Examplecount}{0}
\newenvironment{discussion}{\noindent Discussion.}{}
\pagenumbering{gobble}
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Problem 1
\section*{Problem 1, CS38 Set 7, Matt Lim}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Problem 2
\section*{Problem 2, CS38 Set 7, Matt Lim}
Here is how we will format this problem as an integer linear program. For the
integer linear program, let $e_{uv} = 1$ if
$e_{uv} = (u,v)$ is across the cut and $0$ otherwise. Also, let $x_v = 1$ if
$v \in S$ and $0$ otherwise.
i\[ \textbf{maximize } \sum_{\forall e_{uv}} e_{uv} \]
\[ \textbf{such that} \]
\[ e_{uv} \leq min[x_u + x_v, 2 - (x_u + x_v)] \]
\[ x_v = 0 \text{ or } x_v = 1 \text{ for all $v \in V$} \]
\[ e_{uv} = 0 \text{ or } e_{uv} = 1 \text{ for all $e_{uv} \in E$} \]
Note that solving this ILP gives us the value of the max cut.

Now we will format this problem as a linear program.
\[ \textbf{maximize } \sum_{\forall e_{uv}} e_{uv} \]
\[ \textbf{such that} \]
\[ e_{uv} \leq min[x_u + x_v, 2 - (x_u + x_v)] \]
\[ 0 \leq x_v \leq 1 \text{ for all $v \in V$} \]
\[ 0 \leq e_{uv} \leq 1 \text{ for all $e_{uv} \in E$} \]

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Problem 3
\section*{Problem 3, CS38 Set 7, Matt Lim}
\begin{description}
    \item[(a)]
        We can find a maximal matching in $O(m)$ time using the following
        algorithm. Let the ``value'' of $v_1 = 1$, $v_2 = 2$, etc.

        \vspace{5mm}
        \noindent \textbf{Maximal-matching}$(G = (V,E))$
        \begin{enumerate}
            \item $S = \varnothing$
            \item Initialize array $A$ of size $|V|$ of all zeroes
            \item \textbf{for} each edge $e = (u,v) \in E$
            {\setlength\itemindent{25pt} \item \textbf{if} $A[u] == 0$ and
            $A[v] == 0$ }
            {\setlength\itemindent{50pt} \item add $e$ to $S$ }
            {\setlength\itemindent{50pt} \item $A[u] = 1$ }
            {\setlength\itemindent{50pt} \item $A[v] = 1$ }
            \item return $S$
        \end{enumerate}

        This clearly gives us a maximal matching. The reason we get a
        matching is line 4. This makes sure that no vertices are used
        in more than one edge. The reason we get a maximal matching is
        line 3 and line 4. These lines make it so that if we can add an edge $e$
        to $S$, we do it. And we try every edge. So by the end, we will have
        tried every edge $e$, and if it could have been inserted, we inserted it. So
        there is no edge that can be added to $S$ that would keep it a matching
        (or else we would have added it). Note this reasoning relies on the fact
        that, once we pass up adding an edge, it will never be possible to add
        it at any further point in the algorithm, since can only add more edges
        to $S$ after passing up an edge, which only leaves more vertices
        unavailable.

        This algorithm is $O(m)$ for the following reasons. First of all, the
        for-loop in line 3 iterates through all edges. Then, in
        the for-loop, everything we do is constant time, since we keep an array
        of which vertices we have included, and looking up things in arrays is
        constant time. The only other thing we do in the for loop is add an
        element to a set, which is also constant time. Thus our algorithm runs
        in time $O(m)$.
    \item[(b)]
        Let $S'$ be a maximum matching and $S$ be a maximal matching.
        For every edge $e = (u,v)$ in $S$, we have that $S'$ contains either: an
        edge $e' = (u,v)$; an edge $e'$ containing $u$; an edge $e'$ containing
        $v$; or an edge $e'$ containing $u$ and an edge $e''$ containing $v$. If
        $S'$ doesn't contain any of those possibilities, we have that it is not
        a maximum cardinality matching, as edge $(u,v)$ could be added.
        So, for each edge $e = (u,v) \in S$,
        we lose at most one edge compared to $S'$. That is, for each edge
        $e = (u,v)$ in $S$, we could have at most two edges in $S'$ (one with
        $u$, one with $v$), and at
        least one (the other possibilities). So the cardinality of $S$ is at least
        one-half of the cardinality of $S'$.

        Here we will use the approximation algorithm for vertex cover given in
        lecture 17, slide 30. Let $C$ be an approximation vertex cover and
        $C_{opt}$ be the optimal vertex cover. We have
        the set of the $|C|/2$ pair of vertices, represented as edges $(x,y)$
        that were added to $C$ make up a maximal matching $M$, with $|M| =
        |C|/2$. This is true because we pick edges in a way such that no vertex
        appears in more than one edge, and go through all the vertices (it is
        basically just the same algorithm as we gave in $(a)$, just more
        general). Then we have that, from the slides, $|C| \leq 2|C_{opt}|
        \implies |M| \leq |C_{opt}|$. We also have that $|C$
\end{description}
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Problem 3
\section*{Problem 4, CS38 Set 7, Matt Lim}
Assume $a_1, a_2, \dots, a_n$ are all less than or equal to 1 and greater than
or equal to zero (otherwise we cannot pack some of them).
Let $OPT$ equal the minimum number of bins that can fit $a_1, a_2, \dots, a_n$.
Then we have that $sum(a_1, a_2, \dots, a_n) \leq OPT$, since each bin will
either have some empty space or be completely full.
Let $B$ be the number of bins the approximation algorithm
gives us. Then we have that $B-1$ bins are greater than half full. Otherwise, we
could have used at least one less bin by ``combining'' the contents of two bins.
This gives us the inequality $\sum_i a_i > \frac{B-1}{2}$, since $2 \cdot \sum_i a_i
> B - 1$, since $B-1$ bins are more than half full. Now, we have two cases. If
all $B$ bins are greater than half full, then we get the inequality
$\sum_i a_i > \frac{B}{2}$. If $B-1$ bins are greater than half full
and $1$ bin is less than half full, then consider the following. Let $x$ be the
fullness of $B_k$, the lowest capacity of the $B-1$ bins that are greater than half full.
Let the other bin (less than or equal to half full) be $B_j$. Then we have
that $|B_j|$, which represents how full $B_j$ is, is
greater than $1-x$ (otherwise we could have put it in $B_k$). Now, consider the following.
We have that $\sum_{i \text{ where $a_i \notin B_k,B_j$}} a_i > \frac{B-2}{2}$,
since this inequality considers only bins more than half full. We also have that
$\cdot \sum_{i \text{ where $a_i \in B_k, B_j$}} a_i > x + 1 - x = 1$. So overall,
$\sum_{i} a_i > \frac{B-2}{2} + 1
\implies \sum_{i} a_i > \frac{B}{2}$. So in either case, we have $\sum_{i} a_i >
\frac{B}{2}$. Then, we get that
\[ OPT \geq \sum_i a_i > \frac{B}{2} \]
\[ OPT > \frac{B}{2} \]
\[ 2 \cdot OPT > B \]
This gives us our approximation ratio of 2.
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Problem 3
\end{document}
